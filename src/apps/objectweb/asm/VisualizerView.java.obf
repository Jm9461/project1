package b.d.a;

import android.content.Context;
import android.media.MediaPlayer;
import android.media.audiofx.Visualizer;
import android.media.audiofx.Visualizer.OnDataCaptureListener;

class n
{
  private Visualizer a;
  private MediaPlayer b;
  private Visualizer.OnDataCaptureListener c;
  private int d;
  private long e;
  
  public n(Context paramContext, int paramInt, final b paramB)
  {
    b = MediaPlayer.create(paramContext, k.av_workaround_1min);
    a = new Visualizer(paramInt);
    a.setEnabled(false);
    a.setCaptureSize(Visualizer.getCaptureSizeRange()[1]);
    d = Visualizer.getMaxCaptureRate();
    c = new a(paramB);
    a.setEnabled(true);
  }
  
  public void a()
  {
    a.setEnabled(false);
    a.release();
    a = null;
    b.release();
    b = null;
  }
  
  public void a(boolean paramBoolean)
  {
    Visualizer localVisualizer = a;
    if (localVisualizer == null) {
      return;
    }
    localVisualizer.setEnabled(false);
    if (paramBoolean) {
      a.setDataCaptureListener(c, d, false, true);
    } else {
      a.setDataCaptureListener(null, d, false, false);
    }
    a.setEnabled(true);
  }
  
  class a
    implements Visualizer.OnDataCaptureListener
  {
    a(n.b paramB) {}
    
    public void onFftDataCapture(Visualizer paramVisualizer, byte[] paramArrayOfByte, int paramInt)
    {
      boolean bool = l.a(paramArrayOfByte);
      if (n.a(n.this) == 0L)
      {
        if (bool) {
          n.a(n.this, System.currentTimeMillis());
        }
      }
      else if (!bool)
      {
        n.a(n.this, 0L);
      }
      else if (System.currentTimeMillis() - n.a(n.this) >= 500L)
      {
        a(true);
        n.a(n.this, 0L);
      }
      paramB.a(paramArrayOfByte);
    }
    
    public void onWaveFormDataCapture(Visualizer paramVisualizer, byte[] paramArrayOfByte, int paramInt) {}
  }
  
  public static abstract interface b
  {
    public abstract void a(byte[] paramArrayOfByte);
  }
}
